# Web Scraping and Data Cleansing Tool
This project is a Python-based web scraping and data cleansing tool designed to extract and clean data from licensed liquor premises and suppliers in Hong Kong.

---
## ğŸ“Œ Code Installation  
Before running the script, install the required dependencies:
pip install requests beautifulsoup4 selenium pandas openpyxl
## ğŸš€ Features
âœ… Automated data extraction using Python, BeautifulSoup, and Selenium.
âœ… Data cleaning and preprocessing using Pandas.
âœ… Handles over 50+ cuisine types & multiple district IDs for comprehensive data collection.
âœ… Multi-threaded execution to optimize web scraping performance.
âœ… Exports cleaned data to Excel (.xlsx) format.
## ğŸ“Œ Main Section
### ğŸ“ Web Scraping Code
```
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import WebDriverException, TimeoutException, NoSuchElementException
import time
import pandas as pd
import re
from urllib.parse import quote
import concurrent.futures
import threading
```
## ğŸš— Initializing WebDriver
```
thread_local = threading.local()

def get_driver():
    """Initialize a Chrome WebDriver instance with proper settings."""
    if not hasattr(thread_local, "driver"):
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)')
        thread_local.driver = webdriver.Chrome(options=options)
    return thread_local.driver
```
